{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (1.20.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in d:\\anaconda3\\lib\\site-packages (from pandas) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: nltk in d:\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in d:\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in d:\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: sklearn in d:\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda3\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#visualizing'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html.parser in d:\\anaconda3\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: ply in d:\\anaconda3\\lib\\site-packages (from html.parser) (3.11)\n",
      "Requirement already satisfied: pattern3 in d:\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: docx in d:\\anaconda3\\lib\\site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: simplejson in d:\\anaconda3\\lib\\site-packages (from pattern3) (3.17.5)\n",
      "Requirement already satisfied: pdfminer.six in d:\\anaconda3\\lib\\site-packages (from pattern3) (20211012)\n",
      "Requirement already satisfied: pdfminer3k in d:\\anaconda3\\lib\\site-packages (from pattern3) (1.3.4)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda3\\lib\\site-packages (from pattern3) (4.9.3)\n",
      "Requirement already satisfied: cherrypy in d:\\anaconda3\\lib\\site-packages (from pattern3) (18.6.1)\n",
      "Requirement already satisfied: feedparser in d:\\anaconda3\\lib\\site-packages (from pattern3) (6.0.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda3\\lib\\site-packages (from beautifulsoup4->pattern3) (2.2.1)\n",
      "Requirement already satisfied: portend>=2.1.1 in d:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (3.0.0)\n",
      "Requirement already satisfied: more-itertools in d:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (8.7.0)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in d:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (8.5.2)\n",
      "Requirement already satisfied: jaraco.collections in d:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (3.4.0)\n",
      "Requirement already satisfied: pywin32>=227 in d:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (227)\n",
      "Requirement already satisfied: zc.lockfile in d:\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: jaraco.functools in d:\\anaconda3\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern3) (3.4.0)\n",
      "Requirement already satisfied: six>=1.11.0 in d:\\anaconda3\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern3) (1.15.0)\n",
      "Requirement already satisfied: tempora>=1.8 in d:\\anaconda3\\lib\\site-packages (from portend>=2.1.1->cherrypy->pattern3) (4.1.2)\n",
      "Requirement already satisfied: pytz in d:\\anaconda3\\lib\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2021.1)\n",
      "Requirement already satisfied: Pillow>=2.0 in d:\\anaconda3\\lib\\site-packages (from docx->pattern3) (8.2.0)\n",
      "Requirement already satisfied: lxml in d:\\anaconda3\\lib\\site-packages (from docx->pattern3) (4.6.3)\n",
      "Requirement already satisfied: sgmllib3k in d:\\anaconda3\\lib\\site-packages (from feedparser->pattern3) (1.0.0)\n",
      "Requirement already satisfied: jaraco.text in d:\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (3.6.0)\n",
      "Requirement already satisfied: jaraco.classes in d:\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (3.2.1)\n",
      "Requirement already satisfied: importlib-resources in d:\\anaconda3\\lib\\site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern3) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\anaconda3\\lib\\site-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern3) (3.4.1)\n",
      "Requirement already satisfied: chardet in d:\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (4.0.0)\n",
      "Requirement already satisfied: cryptography in d:\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (3.4.7)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six->pattern3) (1.14.5)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern3) (2.20)\n",
      "Requirement already satisfied: ply in d:\\anaconda3\\lib\\site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from zc.lockfile->cherrypy->pattern3) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyLDAvis in d:\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.24.1)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (52.0.0.post20210125)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.4)\n",
      "Requirement already satisfied: sklearn in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.20.0)\n",
      "Requirement already satisfied: numexpr in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: scipy in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.6.2)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: gensim in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: funcy in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.16)\n",
      "Requirement already satisfied: future in d:\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: Cython==0.29.23 in d:\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn->pyLDAvis) (2.1.0)\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\azzz1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\azzz1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\azzz1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\azzz1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#the module 'sys' allows istalling module from inside Jupyter\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install numpy\n",
    "import numpy as np\n",
    "\n",
    "!{sys.executable} -m pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Natrual Language ToolKit (NLTK)\n",
    "!{sys.executable} -m pip install nltk\n",
    "import nltk\n",
    "\n",
    "!{sys.executable} -m pip install sklearn\n",
    "from sklearn import metrics\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import  CountVectorizer #bag-of-words vectorizer \n",
    "from sklearn.decomposition import LatentDirichletAllocation #package for LDA\n",
    "\n",
    "# Plotting tools\n",
    "\n",
    "from pprint import pprint\n",
    "!{sys.executable} -m pip install pyLDAvis #visualizing LDA\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#define text normalization function\n",
    "%run ./Text_Normalization_Function.ipynb #defining text normalization function\n",
    "\n",
    "#ignore warnings about future changes in functions as they take too much space\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(r'C:\\Users\\azzz1\\OneDrive\\桌面\\562\\2018.csv',sep=',',header='infer',usecols=[9])\n",
    "data.head(5)\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['1', '2', '3', '4']\n",
    "data1 = data[\"reviewText\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_corpus=[x for x in data1 if type(x)==str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data\n",
    "normalized_corpus_news = normalize_corpus(news_corpus)\n",
    "\n",
    "#define a Bag-of-Words vecgtorizer\n",
    "bow_vectorizer_news = CountVectorizer(max_features=1000)\n",
    "\n",
    "#vectorize data\n",
    "bow_news_corpus = bow_vectorizer_news.fit_transform(normalized_corpus_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-854e07f73e51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m lda_news = LatentDirichletAllocation(n_components=2, max_iter=500,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                      \u001b[0mdoc_topic_prior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                      topic_word_prior = 0.9).fit(bow_news_corpus)\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    578\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m                     \u001b[1;31m# batch update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m                     self._em_step(X, total_samples=n_samples,\n\u001b[0m\u001b[0;32m    581\u001b[0m                                   batch_update=True, parallel=parallel)\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_em_step\u001b[1;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;31m# E-step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         _, suff_stats = self._e_step(X, cal_sstats=True, random_init=True,\n\u001b[0m\u001b[0;32m    457\u001b[0m                                      parallel=parallel)\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_e_step\u001b[1;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[0;32m    401\u001b[0m             parallel = Parallel(n_jobs=n_jobs, verbose=max(0,\n\u001b[0;32m    402\u001b[0m                                                            self.verbose - 1))\n\u001b[1;32m--> 403\u001b[1;33m         results = parallel(\n\u001b[0m\u001b[0;32m    404\u001b[0m             delayed(_update_doc_distribution)(X[idx_slice, :],\n\u001b[0;32m    405\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_dirichlet_component_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_update_doc_distribution\u001b[1;34m(X, exp_topic_word_distr, doc_topic_prior, max_iters, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;31m# The next one is a copy, since the inner loop overwrites it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mexp_doc_topic_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_doc_topic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mexp_topic_word_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_topic_word_distr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m# Iterate between `doc_topic_d` and `norm_phi` until convergence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda_news = LatentDirichletAllocation(n_components=2, max_iter=500,\n",
    "                                     doc_topic_prior = 0.9,\n",
    "                                     topic_word_prior = 0.9).fit(bow_news_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare to display result in the Jupyter notebook\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
    "pyLDAvis.sklearn.prepare(lda_news, bow_news_corpus, bow_vectorizer_news, mds='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
